{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat hourly data csv files \n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import np\n",
    "a=['ATL','CLT','DEN','DFW','EWR','IAH','JFK','LAS','LAX','MCO','MIA','ORD','PHX','SEA','SFO']\n",
    "for l in range(0,15):\n",
    "    for y in range(2013,2018):\n",
    "        year=str(y)\n",
    "        file1=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\hourly data\\ '.rstrip()+year+'-'+a[l]+'-hourly-1.csv')\n",
    "        file2=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\hourly data\\ '.rstrip()+year+'-'+a[l]+'-hourly-2.csv')\n",
    "        new=pd.concat([file1,file2])\n",
    "        for i in range(3,13):\n",
    "            no=str(i)\n",
    "            file = pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\hourly data\\ '.rstrip()+year+'-'+a[l]+'-hourly-'+no+'.csv')\n",
    "            new=pd.concat([new,file])\n",
    "        new.to_csv(year+'-'+a[l]+'-hourly.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unwanted airport information #df.isin\n",
    "import pandas as pd\n",
    "a=['ATL','CLT','DEN','DFW','EWR','IAH','JFK','LAS','LAX','MCO','MIA','ORD','PHX','SEA','SFO']\n",
    "for y in range(2013,2018):\n",
    "    for k in range(1,13):\n",
    "        year=str(y)\n",
    "        no=str(k)\n",
    "        df=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\FD\\On_Time_On_Time_Performance_'+year+'_'+no+'.csv',low_memory=False)\n",
    "        df1=df[((df.Origin =='ATL')|(df.Origin =='CLT')|(df.Origin =='DEN')|(df.Origin =='DFW')|(df.Origin =='EWR')|(df.Origin =='IAH')|(df.Origin =='JFK')|(df.Origin =='LAS')|(df.Origin =='LAX')|(df.Origin =='MCO')|(df.Origin =='MIA')|(df.Origin =='ORD')|(df.Origin =='PHX')|(df.Origin =='SEA')|(df.Origin =='SFO'))& ((df.Dest =='ATL')|(df.Dest =='CLT')|(df.Dest =='DEN')|(df.Dest =='DFW')|(df.Dest =='EWR')|(df.Dest =='IAH')|(df.Dest =='JFK')|(df.Dest =='LAS')|(df.Dest =='LAX')|(df.Dest =='MCO')|(df.Dest =='MIA')|(df.Dest =='ORD')|(df.Dest =='PHX')|(df.Dest =='SEA')|(df.Dest =='SFO'))]\n",
    "        df1.to_csv(year+'-flight-'+no+'.csv',index=False,encoding='utf-8')\n",
    "        del df\n",
    "        del df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns from flight data\n",
    "import pandas as pd\n",
    "for num in range(1,13):\n",
    "    for y in range(2013,2018):\n",
    "        year=str(y)\n",
    "        no=str(num)\n",
    "        df1=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\FD1\\ '.rstrip()+year+'-flight-'+no+'.csv',low_memory=False)\n",
    "        df2=df1[['FlightDate','Quarter','Year','Month','DayofMonth','DepTime','DepDel15','CRSDepTime','DepDelayMinutes','Origin','Dest','ArrTime','CRSArrTime','ArrDel15','ArrDelayMinutes']].copy()\n",
    "        df2.to_csv(year+'-flight-'+no+'.csv',index=False,encoding='utf-8')\n",
    "        del df1\n",
    "        del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns from weather data\n",
    "import pandas as pd\n",
    "from pandas import np\n",
    "a=['ATL','CLT','DEN','DFW','EWR','IAH','JFK','LAS','LAX','MCO','MIA','ORD','PHX','SEA','SFO']\n",
    "for l in range(0,15):\n",
    "    for y in range(2013,2018):\n",
    "        year=str(y)\n",
    "        df1=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\hourly concat data\\ '.rstrip()+ year+'-'+a[l]+'-hourly.csv',low_memory=False)\n",
    "        df2=df1[['date','time','tempF','windspeedKmph','winddirDegree','weatherCode','precipMM','humidity','visibility','pressure','cloudcover','DewPointF','WindChillF','WindGustKmph']].copy()\n",
    "        df2['airport'] = a[l]\n",
    "        df2.to_csv(year+'-weather-'+a[l]+'.csv',index=False,encoding='utf-8')\n",
    "        del df1\n",
    "        del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat yearly flight data\n",
    "for y in range(2013,2018):\n",
    "    year=str(y)\n",
    "    new=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\FD2\\ '.rstrip()+year+'-flight-1.csv',low_memory=False)\n",
    "    for i in range(2,13):\n",
    "        no=str(i)\n",
    "        file=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\FD2\\ '.rstrip()+year+'-flight-'+no+'.csv',low_memory=False)\n",
    "        new=pd.concat([new,file])\n",
    "    new.to_csv(year+'-flight.csv',index=False,encoding='utf-8')\n",
    "    del new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat yearly weather data\n",
    "for y in range(2013,2018):\n",
    "    year=str(y)\n",
    "    new=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\W1\\ '.rstrip()+year+'-weather-ATL.csv',low_memory=False)\n",
    "    for i in range(1,15):\n",
    "        file=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\W1\\ '.rstrip()+year+'-weather-'+a[i]+'.csv',low_memory=False)\n",
    "        new=pd.concat([new,file])\n",
    "    new.to_csv(year+'-weather.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(2013,2018):\n",
    "    year=str(y)\n",
    "    df=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\FD3\\ '.rstrip()+year+ '-flight.csv',low_memory=False)\n",
    "    df=df.dropna()\n",
    "    df['time']=((df['DepTime']/100).astype(int))*100\n",
    "    df['airport'] = df['Origin']\n",
    "    vals={'ATL' : 1, 'CLT' : 2, 'DEN' : 3, 'DFW' : 4, 'EWR' : 5, 'IAH' : 6, 'JFK' : 7, 'LAS' : 8, 'LAX' : 9, 'MCO' : 10, 'MIA' : 11, 'ORD' : 12, 'PHX' : 13, 'SEA' : 14, 'SFO' : 15}\n",
    "    df = df.replace({'Origin' : vals}) \n",
    "    df.to_csv(year+'-flight.csv',index=False,encoding='utf-8')\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge on the basis of time and date\n",
    "for y in range(2013,2018):\n",
    "    year=str(y)\n",
    "    df1=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\W2\\ '.rstrip()+year+ '-weather.csv',low_memory=False)\n",
    "    df=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\FD4\\ '.rstrip()+year+ '-flight.csv',low_memory=False)\n",
    "    df = df.rename(columns={'FlightDate': 'date'})\n",
    "    new_df=df.merge(df1,on=['date','time','airport'])\n",
    "    new_df.to_csv(year+'-merged.csv',index=False,encoding='utf-8')\n",
    "    del df\n",
    "    del df1 \n",
    "    del new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\M2\\2013-merged1.csv',low_memory=False)\n",
    "for y in range(2014,2016):\n",
    "    year=str(y)\n",
    "    file=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\M2\\ '.rstrip()+year+'-merged1.csv',low_memory=False)\n",
    "    new=pd.concat([new,file])\n",
    "new.to_csv('train.csv',index=False,encoding='utf-8')\n",
    "del new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(2013,2018):\n",
    "    year=str(y)\n",
    "    df=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\M1\\ '.rstrip()+year+ '-merged.csv',low_memory=False)\n",
    "    df1=pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\W2\\ '.rstrip()+year+ '-weather.csv',low_memory=False)\n",
    "    df1=df1.add_suffix('_d')\n",
    "    df1 = df1.rename(columns={'airport_d': 'Dest','time_d':'time','date_d':'date'})\n",
    "    new_df=df.merge(df1,on=['date','time','Dest'])\n",
    "    new_df.to_csv(year+'-merged1.csv',index=False,encoding='utf-8')\n",
    "    del df\n",
    "    del df1\n",
    "    del new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df= pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\train.csv')\n",
    "vals={'ATL' : 1, 'CLT' : 2, 'DEN' : 3, 'DFW' : 4, 'EWR' : 5, 'IAH' : 6, 'JFK' : 7, 'LAS' : 8, 'LAX' : 9, 'MCO' : 10, 'MIA' : 11, 'ORD' : 12, 'PHX' : 13, 'SEA' : 14, 'SFO' : 15}\n",
    "df = df.replace({'Dest' : vals}) \n",
    "df1=df.drop(['date','time','Year','airport','DepDel15','CRSDepTime','CRSArrTime','ArrDel15','ArrDelayMinutes'], axis=1)\n",
    "df2=df['ArrDel15']\n",
    "X= df1.values\n",
    "y= df2.values\n",
    "X = X.astype(int)\n",
    "y = y.astype(int)\n",
    "df= pd.read_csv(r'C:\\Users\\Marjerie\\Desktop\\test.csv')\n",
    "vals={'ATL' : 1, 'CLT' : 2, 'DEN' : 3, 'DFW' : 4, 'EWR' : 5, 'IAH' : 6, 'JFK' : 7, 'LAS' : 8, 'LAX' : 9, 'MCO' : 10, 'MIA' : 11, 'ORD' : 12, 'PHX' : 13, 'SEA' : 14, 'SFO' : 15}\n",
    "df = df.replace({'Dest' : vals}) \n",
    "df3=df.drop(['date','time','airport','Year','DepDel15','CRSDepTime','CRSArrTime','ArrDel15','ArrDelayMinutes'], axis=1)\n",
    "df4=df['ArrDel15']\n",
    "X_test= df3.values\n",
    "y_test= df4.values\n",
    "X_test = X_test.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE()\n",
    "X_rtrain, y_rtrain = sm.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9950179374034779\n",
      "[[694844  23981]\n",
      " [ 58304 137186]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94    718825\n",
      "          1       0.85      0.70      0.77    195490\n",
      "\n",
      "avg / total       0.91      0.91      0.91    914315\n",
      "\n",
      "0.9100036639451392\n",
      "[0.03597055 0.02820142 0.01245523 0.02888879 0.55573238 0.01368114\n",
      " 0.01117118 0.02333651 0.01147026 0.01738235 0.0122775  0.00948768\n",
      " 0.01397588 0.01094375 0.0081209  0.01190801 0.01633246 0.01074657\n",
      " 0.01097797 0.01104278 0.01025178 0.0179306  0.01192505 0.01021049\n",
      " 0.0117426  0.01084894 0.01086234 0.01102294 0.0190144  0.01059467\n",
      " 0.01005739 0.01143553]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn as sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "model = RandomForestClassifier(criterion='gini')\n",
    "model.fit(X_rtrain, y_rtrain)\n",
    "score=model.score(X_rtrain,y_rtrain)\n",
    "print (score)\n",
    "predicted= model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predicted))  \n",
    "print(classification_report(y_test,predicted))  \n",
    "print(accuracy_score(y_test,predicted)) \n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990403875991621\n",
      "[[702294  16531]\n",
      " [ 63607 131883]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95    718825\n",
      "          1       0.89      0.67      0.77    195490\n",
      "\n",
      "avg / total       0.91      0.91      0.91    914315\n",
      "\n",
      "0.9123518699791647\n",
      "[0.00341561 0.00839046 0.01466145 0.04058074 0.54550741 0.0112714\n",
      " 0.01090127 0.04339526 0.01623776 0.01484511 0.02081957 0.00714946\n",
      " 0.00419814 0.0173189  0.00446338 0.01507808 0.01516683 0.01623228\n",
      " 0.01714728 0.01525749 0.01547878 0.01484595 0.02013719 0.00699369\n",
      " 0.00290015 0.01731181 0.00445402 0.01454693 0.01470728 0.01603075\n",
      " 0.01562238 0.0149332 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn as sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "model = RandomForestClassifier(criterion='gini')\n",
    "model.fit(X, y)\n",
    "score=model.score(X,y)\n",
    "print (score)\n",
    "predicted= model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predicted))  \n",
    "print(classification_report(y_test,predicted))  \n",
    "print(accuracy_score(y_test,predicted)) \n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9131959083634821\n",
      "[[701543  17282]\n",
      " [ 60270 135220]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95    718825\n",
      "          1       0.89      0.69      0.78    195490\n",
      "\n",
      "avg / total       0.91      0.92      0.91    914315\n",
      "\n",
      "0.9151802168836779\n",
      "[0.0016773  0.00862259 0.00092217 0.05079427 0.39363246 0.05404125\n",
      " 0.04701708 0.12074974 0.02408183 0.00921216 0.00962315 0.02670175\n",
      " 0.00991755 0.00094735 0.01308116 0.02485369 0.00197577 0.00182013\n",
      " 0.04284232 0.00222038 0.00731218 0.01260238 0.01789435 0.01246147\n",
      " 0.00816903 0.01488951 0.01397521 0.01396345 0.02131524 0.01582158\n",
      " 0.00471724 0.01214426]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn as sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X, y)\n",
    "score=model.score(X,y)\n",
    "print (score)\n",
    "predicted= model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predicted))  \n",
    "print(classification_report(y_test,predicted))  \n",
    "print(accuracy_score(y_test,predicted)) \n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2706301, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2706301,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914315, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914315,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
